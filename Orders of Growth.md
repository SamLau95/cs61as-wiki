While it difficult to predict exactly how much time a function will take to run because of differences in processor speeds and other factors, it is still possible to characterize functions by their orders of growth, a measurement of how a function's resource usage grows given differently sized inputs. In nearly all cases of orders of growth, we use a function's asymptotic behavior, or how a function behaves given large inputs. Orders of growth are typically used to characterize an algorithm's running time and memory usage.

The [most common notations](http://en.wikipedia.org/wiki/Big_O_notation#Family_of_Bachmann.E2.80.93Landau_notations) of specifying orders of growth include: 

- [Big O notation](wiki:big-o-notation), which specifies an upper bound and is most widely used.
- Big Omega notation, which specifies a lower bound
- Theta notation, which specifies both a lower and an upper bound